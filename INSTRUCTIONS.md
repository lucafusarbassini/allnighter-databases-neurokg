## REQUIREMENTS

- üíª OS: Any (linux-based prefered)
- üê≥ Docker: `docker --version` should not give errors.
- üì¶ Poetry: in ubuntu i just did `sudo apt install python3-poetry`
- üêç Python + `pip install biocypher`: only if you want local testings before running the dockers

## DOCKER

- This will pull images (first time), create containers 'build' (runs create_knowledge_graph.py), 'import' (to neo4j), 'deploy' (serve) + a volume and run them sequentially. Only 'deploy' remains up and running. To run the pipeline:
    ```bash
    docker compose up -d
    ```
- To show logs:
    ```bash
    docker logs build
    docker logs import
    docker logs deploy
    ```
- To stop running containers ('deploy'):
    ```bash
    docker compose stop
    ```
- To restart the 'deploy' container:
    ```bash
    docker compose start deploy
    ```
- To stop and REMOVE all containers (you need to re-run the first command afterwards):
    ```bash
    docker compose down # stops 'deploy' (if running) and remove containers
    docker compose down -v # also remove/reset volumes, but it seems to be unnecessary
    ```
- Checks
    ```bash
    docker ps -a # containers
    docker images # images
    ```
- If 'deploy' is running, neo4j is serving at http://localhost:7474/browser/
- Do not change the top level workspace directory structure. Work in "./template_package" and structure subfolders as you like for the adapters, AVOID changes in "./docker" and "./scripts", modify when needed "config/schema_config.yaml" (other configs currently work as exepected).

## Dependencies

- If you are using a new python package, add to poetry and rerun the docker pipeline:
    ```bash
    poetry add <package_name> # e.g 'poetry add pyarrow' for reading parquet files with pandas
    poetry install # updates lock/toml files
    ```

## Biocypher documentation

Click here to [go to Quickstart page](https://biocypher.org/BioCypher/learn/quickstart/)
Biocypher helps connecting ontology(ies) to the nodes of the graph. Click here for the BioLink [nodes default Ontology](https://biolink.github.io/biolink-model/categories.html) and for the [relationships Ontology](https://biolink.github.io/biolink-model/associations.html). You must use EXACT names from the base ontology BUT converted in 'sentence case' in the schema config (ontology uses "PascalCase"). Both nodes and edges can have properties. The following is an example of a schema configuration:
### schema_config.yaml specifications
Here the [schema configuration reference](https://biocypher.org/BioCypher/reference/schema-config/) with all available fields (more than the ones below). An example:
```yaml
gene:                    # exact name from base ontology, BUT in lower case + spaces
  represented_as: node      # 'node' or 'edge'. Even relationship can be reified as node if needed
  preferred_id: uniprot     # namespace from which the id comes from (if any).
  input_label: Gene      # exact same label you use in the adapter output (nodes yielder function)
  properties:                # represent the property dictionary optionally generated by the adapter. Any key absent in this config will be ignored from the adapter output
    mass: float             # str, int, float, bool.
    name: str

quaternary structure:
  is_a: macromolecular complex       # explicit subclassing. Extends the ontology by adding the child 'QuaternaryStructure' to 'MacromolecularComplex', the latter is an exact name from the base ontology
  represented_as: node
  input_label: QuaternaryStructure

ligand receptor interaction:                
  is_a: pairwise molecular interaction
  represented_as: edge                      # edge in the final graph. Adapter must yield source and target node ids in specific order. Set always to "edge" for relationships (never do reification)
  input_label: LigandReceptorInteraction
  properties:                              
    species: str[]                          # can be arrays -> str[], int[], float[], bool[]. E.g ["Mus musculus", "Home sapiens"] means relation happens in both species and gene orthology is implied

#=========    INHERITED NODES example
gene isoform:
  is_a: gene                            
  inherit_properties: true              # will have the same properties of "gene" define above
  represented_as: node
  preferred_id: uniprot
  input_label: gene_isoform
```

### Adapters

It's a python class and the core of the database-to-graph mechanism, it loads, preprocesses and outputs data.
It must implement two functions that produces ORDERED tuples: 
* Node generator -> yield a 3-tuple: unique entity id (namespace is preferred_id in the schema), the input_label (matching exactly the schema_config.yaml) and a property dictionary.
* Edge generator -> yield a 5-tuple: id (can be None), node source id, node target id, relationship label (schema input_label), property dictionary.
Exact order: Node -> (id, label, props); Edge -> (id, source, target, label, props)
Props can be an empty dictionary.

In the case of properties that are not present in (some of) the source data but defined in the schema_config, BioCypher will add them to the output with a default value of None. Additional properties in the input that are not represented in the schema will be ignored (e.g adapter yields a props dictionary with key "chromosome" but no such key in the schema yaml -> ignored and no such prop for that node/edge type in the final graph)

**IMPORTANT note**: biocypher internally produces some CSV files that are then imported into neo4j -> be sure to sanitize eventual quotes (should be rare) in string fields in the adapter, like some textual properties such as gene descriptions, if the data needs it (i.e. replace " with "" to avoid csv failure).

Reference example:

```python
import pandas as pd
import biocypher
from biocypher._logger import logger

class LianaAdapter:
    def __init__(self):
        self.human_file = "template_package/data/liana_humanconsensus_db.parquet"
        self.mouse_file = "template_package/data/liana_mouseconsensus_db.parquet" # this source already uses human id (ortholog) for mouse genes
        self.data = self._load_data()

    def _load_data(self):
        """
        Loads and merges the mouse and human parquet files.
        The parquet files are expected to have columns: 'source', 'target', 'species'
        """
        logger.info("Loading Parquet files...")

        try:
            df_human = pd.read_parquet(self.human_file)
            if "species" not in df_human.columns:
                df_human["species"] = "Homo sapiens"
        except FileNotFoundError:
            logger.warning(f"File {self.human_file} not found. Skipping.")
            df_human = pd.DataFrame()

        try:
            df_mouse = pd.read_parquet(self.mouse_file)
            if "species" not in df_mouse.columns:
                df_mouse["species"] = "Mus musculus"
        except FileNotFoundError:
            logger.warning(f"File {self.mouse_file} not found. Skipping.")
            df_mouse = pd.DataFrame()

        # Combine datasets
        full_df = pd.concat([df_human, df_mouse], ignore_index=True)
        merged_species = (
            full_df.groupby(["source", "target"])["species"]
              .apply(lambda x: sorted(set(x)))   # deduplicate + sort
              .reset_index()
        )

        # Validate required columns exist
        required_cols = ['source', 'target', 'species']
        missing_cols = [col for col in required_cols if col not in merged_species.columns]
        if missing_cols:
            raise ValueError(f"Missing required columns: {missing_cols}. Found columns: {merged_species.columns.tolist()}")

        logger.info(f"Loaded {len(merged_species)} interactions from {full_df['species'].nunique()} species.")
        logger.info(f"Species distribution: only human -> {(merged_species['species'].apply(lambda x: x == ['Homo sapiens'])).sum()}, only mouse -> {(merged_species['species'].apply(lambda x: x == ['Mus musculus'])).sum()}, both -> {(merged_species['species'].apply(lambda x: x == ['Homo sapiens', 'Mus musculus'])).sum()}")
        
        return merged_species

    def get_nodes(self):
        """
        Generator yielding nodes.
        Format: (id, label, properties)
        
        Each unique protein (from ligand or receptor columns) becomes a node.
        If an entry starts with "COMPLEX:" (e.g. "COMPLEX:P04626_P21860") it is treated as a QuaternaryStructure.
        No species in nodes -> species is stored as a property in edges.
        """
        logger.info("Generating Nodes...")

        # Map id -> {"species": species, "label": "Gene"|"QuaternaryStructure"}
        node_to_label = {}

        for _, row in self.data.iterrows():
            for col in ("source", "target"):
                pid = row[col]

                if pd.isna(pid):
                    continue

                pid_str = str(pid)

                if pid_str.startswith("COMPLEX:") or "_" in pid_str:
                    label = "QuaternaryStructure"
                    pid_str = pid_str.replace("COMPLEX:", "")
                else:
                    label = "Gene" # Maps to the schema "input_label:"

                if pid_str not in node_to_label:
                    node_to_label[pid_str] = label

        # Yield nodes
        for protein_id, label in node_to_label.items():
            yield (
                protein_id,
                label,
                {}
            )

        logger.info(f"Generated {len(node_to_label)} unique protein/complex nodes.")

    def get_edges(self):
        """
        Generator yielding edges.
        Format: (id, source_id, target_id, label, properties)
        
        Each row represents a ligand-receptor interaction.
        """
        logger.info("Generating Edges...")
        for _, row in self.data.iterrows():
            ligand = row["source"]
            receptor = row["target"]
            species = row["species"]

            if ligand.startswith("COMPLEX:") or "_" in ligand:
                ligand = ligand.replace("COMPLEX:", "")
            if receptor.startswith("COMPLEX:") or "_" in receptor:
                receptor = receptor.replace("COMPLEX:", "")

            # Additional properties beyond species can be added here
            properties = {"species": species}
            #rel_id = f'{ligand}_{receptor}_{species}'  # Unique edge id
            # With id = None, Biocypher deduplicates based on ONLY source, target, label ! (not properties) -> it keeps the first occurrence of the edge. Okay here since we merged same source-target pair with different species into one with a list of species, so 0 duplicates.
            yield (
                None,        # id
                ligand,      # Source (ligand), mandatory
                receptor,    # Target (receptor), mandatory
                "LigandReceptorInteraction", # Maps to schema "input_label:", mandatory
                properties   # optional
            )
        
        logger.info(f"Generated {len(self.data)} interaction edges.")
```

### create_knowledge_graph.py

Main file (at workspace top level) that runs and connects biocypher with the adapters. Biocypher pkg handles schema connection, deduplication, outputs etc. Example:

```python
import biocypher
from template_package.adapters.liana_adapter import LianaAdapter
from biocypher._logger import logger 

# 1. Instantiate Adapter
adapter = LianaAdapter()
# another_adapter = ...

# 2. Instantiate BioCypher Driver
# This reads the schema_config.yaml and biocypher_config.yaml automatically
driver = biocypher.BioCypher()

# 3. Run the driver with the adapter generators
driver.write_nodes(adapter.get_nodes())
driver.write_edges(adapter.get_edges())
# driver.write_nodes(another_adapter.get_nodes())
# ... and so on (can use a loop when we have several adapters)
driver.write_import_call()

# 5. Output Summary
logger.info(
    "Import complete. Check the 'biocypher-out' directory for CSVs and import scripts."
)
```

## Graph Philosophy: Data Integration Rules

The following structural decisions are strict requirements for the data integration process (adapters and schema):

**Unified "Gene" Entity**

* Genes and their corresponding proteins are merged into a single entity class labeled **"Gene"**. This node represents the abstract concept of the biological unit (the gene and its gene product).
* The `preferred_id` for this class is **uniprot**. We prioritize UniProt over HGNC or similar because it provides the most comprehensive and cross-species coverage.

* No "Encoded By" Edges: Since the gene and protein are collapsed into the same node, there must be no edges representing the central dogma (e.g., `encodes`, `is_translated_to`) between a gene and itself.

* The biological nature of the node (whether it acts as DNA or Protein) is determined strictly by its **relationships (edges)**. Users will interpret the node based on the interaction context.
    * *Example:* `(Gene A)-[interacts_with]->(Gene B)` implies that Protein A physically interacts with Protein B.
    * *Example:* `(Gene X)-[regulates_expression_of]->(Gene A)` implies that Protein X (e.g transcription factor) binds to the DNA promoter region of Gene A.

Here is a rewritten version of your **Human-Centered approach**. I have structured it to separate the *data filtering rules* from the *mapping logic* and the *schema implementation*.

---

### Human-Centric Data Strategy

We prioritize a human-centric graph structure. Mouse data is projected onto human nodes via orthology mapping, other species are discarded.

* **Allowed Species:** *Homo sapiens* and *Mus musculus*.

**Orthology Mapping & Node Identity**

You have a json containg a dictionary that maps mouse uniprot ids (key) to the human ortholog id (value) here: "template_package\mappings\mouse_to_human_orthologs.json"
Content exmaple:
{
  "Q8R0Y6": "O75891", # mouse gene Q8R0Y6 maps to human O75891
  "Q05738": "Q05066",
  ...,
}

* **Primary Goal:** Graph nodes ("Gene") should primarily represent **Human** genes (using Human UniProt IDs).
* **Mouse Data Projection:** Relationships involving Mouse genes must be mapped to their **Human orthologs**.
* *Standard Case:* Retrieve the Human ortholog for the Mouse gene. Set the Node ID (first tuple element) to the **Human UniProt ID**.
* *Exception:* In the rare case where no orthology mapping exists, use the **Mouse UniProt ID** as the Node ID.

**Provenance Tracking (Edge Properties)**
To preserve the source of the data (especially when multiple mouse orthologs map to a single human gene), we utilize specific Edge properties:

* **`species`**: Indicates the biological context of the evidence.
* Values: `"Homo sapiens"` or `"Mus musculus"`.

* **`original_id`**: Stores the source ID *before* mapping was applied.

**4. Mapping Implementation Logic**
When processing an input interaction:

* **If input is Human:**
* **Node ID:** Human UniProt ID.
* **Edge `species`:** `"Homo sapiens"`. (Ignore original id, biocypher sets to None by default)

* **If input is Mouse:**
* **Node ID:** **Human** UniProt ID (the mapped target via the orthology json).
* **Edge `species`:** `"Mus musculus"`.
* **Edge `original_id`:** **Mouse** UniProt ID (the source ID).
* *Note:* This preserves granularity. If 6 different mouse genes map to 1 human gene, the graph shows 6 edges connected to that human node, distinguishable by their `original_id`. If no human ortholog -> use source mouse id.

